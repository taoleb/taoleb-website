---
id: "deepseek-v3-1-ue8m0-fp8-explanation"
title: "DeepSeekV3.1里面提到的UE8M0 FP8到是个啥？"
description: "深度解析DeepSeek V3.1中UE8M0 FP8技术的原理、优势及其对国产AI芯片发展的重要意义"
date: "2025-08-25"
pubDate: "2025-08-25"
updatedDate: "2025-08-25"
categories: "AI技术"
tags: ["DeepSeek", "FP8", "UE8M0", "AI芯片", "技术解析", "国产芯片", "大模型"]
cover: "https://wp-cdn.4ce.cn/v2/xJAmwtu.png"
heroImage: ""
recommend: true
top: false
hide: false
---

# DeepSeekV3.1里面提到的UE8M0 FP8到是个啥？

> 深度解析DeepSeek V3.1中UE8M0 FP8技术的原理、优势及其对国产AI芯片发展的重要意义

## 🚀 技术背景

DeepSeek V3.1发布后，一则官方留言让整个AI圈都轰动了：**"新的架构、下一代国产芯片"**，总共短短不到20个字，却蕴含了巨大信息量。这个UE8M0 FP8到底是个啥？下一代国产芯片，又是指什么？

## 🔍 UE8M0 FP8技术解析

### 什么是UE8M0 FP8？

"UE8M0 FP8"这个概念，可以拆分成前后两个部分来解释：

- **前面的UE8M0**：是MXFP8路径里的"缩放因子"
- **后面的FP8**：是把常规浮点格式压缩到8 bit的一种编码方式

### MXFP8技术原理

MXFP8是Open Compute Project在2023年发布的《Microscaling (MX) Formats Specification v1.0》里定义的8 bit微缩块格式。其核心思想是：

1. **分块处理**：先把张量切成固定长度的"块"
2. **独立缩放**：为每个块单独指定一个2的整数次幂作为"缩放因子"
3. **统一编码**：把块内所有数一起除以这个系数后再写成FP8

这种块级（而不是全张量级）的缩放，让MXFP8既保留了8 bit位宽，又把可用动态范围扩展了几十倍。

### UE8M0格式详解

UE8M0中的各个字母代表：

- **U**：表示无符号（有符号可表示为S或省略不写）
- **E8**：8个bit分配给指数位
- **M0**：0个bit分配给尾数位

其他常用的格式还有：
- **E4M3**：4个bit给指数位，3个bit给尾数位
- **E5M2**：5个bit给指数位，2个bit给尾数位

## ⚡ UE8M0 FP8的技术优势

### 1. 计算效率提升

由于UE8M0不含尾数与符号位，处理器在根据缩放因子对数据进行复原时：
- 只需要乘以对应的2的幂
- 也就是移动一下指数位
- 不需要浮点乘法、规格化或舍入逻辑
- 缩短了时钟关键路径

### 2. 动态范围扩展

UE8M0的动态范围覆盖2^(−127)到2^128：
- 指数表可轻松容纳这一跨度
- 为后续块缩放提供充足空间
- 解决单尺度FP8无法同时顾及大/小值的问题

### 3. 精度损失减少

将UE8M0作为分块的尺度后：
- 错误率曲线从整张曲线下降到一条远低水平的横线
- 在保持8 bit张量精度的同时大幅减少信息损失
- 有效避免溢出或被压成0的问题

## 🎯 为什么适配"下一代国产芯片"？

### 当前国产芯片现状

大部分已量产的国产AI加速器仍沿用：
- FP16/BF16 + INT8的计算通路
- 并未集成E4M3/E5M2这类完整的FP8乘加单元

### 新一代芯片的FP8支持

2025年下半年首发的部分新款国产芯片已经在宣传资料里列出：
- **摩尔线程MUSA 3.1 GPU**：原生FP8支持
- **芯原VIP9000 NPU**：Block FP8支持
- 与DeepSeek、华为等15家厂商联合验证UE8M0格式

### 带宽优化的重要性

虽然下一代国产芯片已经在为FP8做出准备，但HBM/LPPDDR带宽仍然与顶尖芯片存在较大差距。而UE8M0让：
- 一组32个FP8数据只追加8bit缩放因子
- 相比传统的4B（32bit）FP32缩放直接节省75%的流量
- 这种空间节约措施被视作下一代架构的重要优化方向

## 🔮 哪些国产芯片厂商受益？

### 首批适配厂商

根据"DeepSeek大模型适配"的8家厂商名单，主要包括：

#### 1. 寒武纪
- MLU370-S4、思元590及最新690系列芯片均支持FP8计算
- 在架构设计和低精度计算优化上一直相对比较领先
- 市场反应：今日早盘盘中大涨近14%，总市值超4940亿元

#### 2. 海光
- 深算三号DCU支持FP8计算
- 存在进一步优化的空间

#### 3. 沐曦
- 今年7月发布的曦云C600支持FP8精度计算

#### 4. 中昊芯英
- "刹那"TPU AI芯片支持FP8精度

#### 5. 摩尔线程
- 国内极少数原生支持FP8的GPU厂商
- 旗舰产品MTT S5000支持FP8精度计算

### 即将上车的厂商

#### 华为昇腾
- 昇腾910B和910C暂不支持原生FP8
- 官方路线图已经写明"2025Q4原生FP8"
- 预计2026年推出的910D（可能的命名）可能是所谓的"下一代芯片"

## 💡 技术意义与影响

### 软硬协同生态

DeepSeek通过改动精度格式，相当于主动贴合国产芯片的最佳性能点，这种软硬协同的模式无疑是把国产芯片们拉进了一个统一的生态坐标系。

### 减少对外依赖

这代表了国产AI正走向软硬协同阶段，能够实质性减少对英伟达、AMD等国外算力的依赖。

### 性价比提升

由于UE8M0 FP8精度格式所具备的优势：
- 更小的带宽
- 更低的功耗
- 更高的吞吐

这意味着同样的硬件今后能跑更大的模型，所以国产芯片的"性价比"被大幅拉高了。

## 📊 市场反应

### 股价表现

- **寒武纪**：今日早盘盘中大涨近14%，总市值超4940亿元，超过中芯国际跃居科创板头名
- **半导体ETF**：半天时间里大涨5.89%
- **科创50**：大涨3%创近三年半新高

### 行业影响

国产芯片概念集体高开，芯片产业链集体走强，市场对这项技术的认可度可见一斑。

## 🔬 技术实现细节

### DeepSeek的开源项目

DeepSeek之前开源的5.6k星标项目FP8 GEMM内核DeepGEMM就已经支持UE8M0，不过这个项目主要是适配英伟达芯片和CUDA生态。

### 技术标准

UE8M0 FP8技术基于Open Compute Project的开源标准，这意味着：
- 技术规范公开透明
- 便于行业协作和生态建设
- 降低技术壁垒

## 🌟 未来展望

### 技术发展趋势

1. **精度格式优化**：更多厂商将采用UE8M0 FP8等先进精度格式
2. **软硬协同**：AI模型与芯片架构的深度适配将成为常态
3. **生态建设**：国产AI技术栈将形成完整的软硬件生态

### 应用场景扩展

UE8M0 FP8技术的应用将不仅限于大语言模型：
- 计算机视觉
- 语音识别
- 推荐系统
- 自动驾驶
- 其他AI应用领域

## 📝 启示

UE8M0 FP8技术代表了AI计算精度格式的重要创新，通过块级缩放和优化的指数位分配，在保持8bit精度的同时大幅提升了计算效率和动态范围。

对于国产AI芯片来说，这项技术的意义不仅在于技术本身的先进性，更在于它标志着国产AI正走向软硬协同的新阶段。通过DeepSeek等AI厂商与国产芯片厂商的深度合作，国产AI技术栈正在形成完整的生态闭环。

这种软硬协同的模式，就像当年的"Wintel联盟"一样，通过深度技术绑定，筑起了AI领域的生态护城河。随着更多厂商加入这个生态，国产AI的竞争力将得到显著提升，在全球AI竞争中占据更有利的位置。

